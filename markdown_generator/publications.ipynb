{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a TSV of publications with metadata and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). The core python code is also in `publications.py`. Run either from the `markdown_generator` folder after replacing `publications.tsv` with one containing your data.\n",
    "\n",
    "TODO: Make this work with BibTex and other databases of citations, rather than Stuart's non-standard TSV format and citation style.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format\n",
    "\n",
    "The TSV needs to have the following columns: pub_date, title, venue, excerpt, citation, site_url, and paper_url, with a header at the top. \n",
    "\n",
    "- `excerpt` and `paper_url` can be blank, but the others must have values. \n",
    "- `pub_date` must be formatted as YYYY-MM-DD.\n",
    "- `url_slug` will be the descriptive part of the .md file and the permalink URL for the page about the paper. The .md file will be `YYYY-MM-DD-[url_slug].md` and the permalink will be `https://[yourdomain]/publications/YYYY-MM-DD-[url_slug]`\n",
    "\n",
    "This is how the raw file looks (it doesn't look pretty, use a spreadsheet or other program to edit and create)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"title\": \"Down with the Hierarchy: The 'H' in HNSW stands for 'Hubs'\",\n",
      "        \"pub_date\": \"2025-01-22\", \n",
      "        \"url_slug\": \"flatnav-paper\", \n",
      "        \"paper_url\": \"https://arxiv.org/pdf/2412.01940\",\n",
      "        \"teaser_url\": \"\",\n",
      "        \"venue\": \"(Preprint)\", \n",
      "        \"acceptance_rate\": \"\",\n",
      "        \"acceptance_type\": \"\",\n",
      "        \"citation\": \"<i>(Preprint)</i> <u>Blaise Munyampirwa</u>, Vihan Lakshman, Benjamin Coleman. <b>&quot;Down with the Hierarchy: The 'H' in HNSW stands for 'Hubs'&quot;</b>.\",\n",
      "        \"excerpt\": \"Driven by recent breakthrough advances in neural representation learning, approximate near-neighbor (ANN) search over vector embeddings has emerged as a critical computational workload. With the introduction of the seminal Hierarchical Navigable Small World (HNSW) algorithm, graph-based indexes have established themselves as the overwhelmingly dominant paradigm for efficient and scalable ANN search. As the name suggests, HNSW searches a layered hierarchical graph to quickly identify neighborhoods of similar points to a given query vector. But is this hierarchy even necessary? A rigorous experimental analysis to answer this question would provide valuable insights into the nature of algorithm design for ANN search and motivate directions for future work in this increasingly crucial domain. To that end, we conduct an extensive benchmarking study covering more large-scale datasets than prior investigations of this question. We ultimately find that a flat navigable small world graph graph retains all of the benefits of HNSW on high-dimensional datasets, with latency and recall performance essentially identical to the original algorithm but with less memory overhead. Furthermore, we go a step further and study why the hierarchy of HNSW provides no benefit in high dimensions, hypothesizing that navigable small world graphs contain a well-connected, frequently traversed 'highway' of hub nodes that maintain the same purported function as the hierarchical layers. We present compelling empirical evidence that the Hub Highway Hypothesis holds for real datasets and investigate the mechanisms by which the highway forms. The implications of this hypothesis may also provide future research directions in developing enhancements to graph-based ANN search.\"\n",
      "    }\n",
      "]"
     ]
    }
   ],
   "source": [
    "!cat publications.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pandas\n",
    "\n",
    "We are using the very handy pandas library for dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import TSV\n",
    "\n",
    "Pandas makes this easy with the read_csv function. We are using a TSV, so we specify the separator as a tab, or `\\t`.\n",
    "\n",
    "I found it important to put this data in a tab-separated values format, because there are a lot of commas in this kind of data and comma-separated values can get messed up. However, you can modify the import statement, as pandas also has read_excel(), read_json(), and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>url_slug</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>teaser_url</th>\n",
       "      <th>venue</th>\n",
       "      <th>acceptance_rate</th>\n",
       "      <th>acceptance_type</th>\n",
       "      <th>alternative_url</th>\n",
       "      <th>citation</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Down with the Hierarchy: The 'H' in HNSW stand...</td>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>flatnav-paper</td>\n",
       "      <td>https://arxiv.org/pdf/2412.01940</td>\n",
       "      <td></td>\n",
       "      <td>(Preprint)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>&lt;i&gt;(Preprint)&lt;/i&gt; &lt;u&gt;Blaise Munyampirwa&lt;/u&gt;, V...</td>\n",
       "      <td>Driven by recent breakthrough advances in neur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title    pub_date  \\\n",
       "0  Down with the Hierarchy: The 'H' in HNSW stand...  2025-01-22   \n",
       "\n",
       "        url_slug                         paper_url teaser_url       venue  \\\n",
       "0  flatnav-paper  https://arxiv.org/pdf/2412.01940             (Preprint)   \n",
       "\n",
       "  acceptance_rate acceptance_type alternative_url  \\\n",
       "0                                                   \n",
       "\n",
       "                                            citation  \\\n",
       "0  <i>(Preprint)</i> <u>Blaise Munyampirwa</u>, V...   \n",
       "\n",
       "                                             excerpt  \n",
       "0  Driven by recent breakthrough advances in neur...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publications = pd.read_json(\"publications.json\")\n",
    "publications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escape special characters\n",
    "\n",
    "YAML is very picky about how it takes a valid string, so we are replacing single and double quotes (and ampersands) with their HTML encoded equivilents. This makes them look not so readable in raw format, but they are parsed and rendered nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the markdown files\n",
    "\n",
    "This is where the heavy lifting is done. This loops through all the rows in the TSV dataframe, then starts to concatentate a big string (```md```) that contains the markdown for each type. It does the YAML metadata first, then does the description for the individual page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for row, item in publications.iterrows():\n",
    "    md_filename = str(item.pub_date) + \"-\" + item.url_slug + \".md\"\n",
    "    html_filename = str(item.pub_date) + \"-\" + item.url_slug\n",
    "    year = item.pub_date[:4]\n",
    "    \n",
    "    ## YAML variables\n",
    "    md = \"---\\ntitle: \\\"\"   + item.title + '\"'\n",
    "    md += \"\\ncollection: publications\"\n",
    "    md += f'\\nurlslug: \"{item.url_slug}\"'\n",
    "    md += \"\"\"\\npermalink: /publication/\"\"\" + html_filename\n",
    "    if len(str(item.excerpt)) > 5:\n",
    "        md += \"\\nexcerpt: '\" + html_escape(item.excerpt) + \"'\"\n",
    "    md += \"\\ndate: \" + str(item.pub_date) \n",
    "    md += \"\\nvenue: '\" + html_escape(item.venue) + \"'\"\n",
    "    if len(str(item.paper_url)) > 5:\n",
    "        md += \"\\npaperurl: '\" + item.paper_url + \"'\"\n",
    "    if len(str(item.acceptance_rate)) > 0:\n",
    "        md += \"\\nacceptancerate: '\" + item.acceptance_rate + \"'\"\n",
    "    if len(str(item.acceptance_type)) > 0:\n",
    "        md += \"\\nacceptancetype: '\" + item.acceptance_type + \"'\"\n",
    "    if len(str(item.alternative_url)) > 5:\n",
    "        md += \"\\nalternativeurl: '\" + item.alternative_url + \"'\"\n",
    "    if len(str(item.teaser_url)) > 5:\n",
    "        md += \"\\nteaserurl: '\" + item.teaser_url + \"'\"\n",
    "    md += \"\\ncitation: '\" + html_escape(item.citation) + \"'\"\n",
    "    md += \"\\n---\"\n",
    "    \n",
    "    ## Markdown description for individual page\n",
    "    if len(str(item.excerpt)) > 5:\n",
    "        md += \"\\n\" + html_escape(item.excerpt) + \"\\n\"\n",
    "    if len(str(item.paper_url)) > 5 and \"internal\" not in str(item.paper_url):\n",
    "        md += \"\\n[Download](\" + item.paper_url + \")\\n\"  \n",
    "    md += f\"\\nCitation: {item.citation} \"\n",
    "    if len(str(item.acceptance_type)) > 0:\n",
    "        md += f\"({item.acceptance_type}) \"\n",
    "    if len(str(item.acceptance_rate)) > 0:\n",
    "        md += f\"(acceptance-rate: {item.acceptance_rate}) \"\n",
    "    md_filename = os.path.basename(md_filename)\n",
    "    with open(\"../_publications/\" + md_filename, 'w') as f:\n",
    "        f.write(md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files are in the publications directory, one directory below where we're working from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-22-flatnav-paper.md\n"
     ]
    }
   ],
   "source": [
    "!ls ../_publications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "title: \"Down with the Hierarchy: The 'H' in HNSW stands for 'Hubs'\"\n",
      "collection: publications\n",
      "urlslug: \"flatnav-paper\"\n",
      "permalink: /publication/2025-01-22-flatnav-paper\n",
      "excerpt: 'Driven by recent breakthrough advances in neural representation learning, approximate near-neighbor (ANN) search over vector embeddings has emerged as a critical computational workload. With the introduction of the seminal Hierarchical Navigable Small World (HNSW) algorithm, graph-based indexes have established themselves as the overwhelmingly dominant paradigm for efficient and scalable ANN search. As the name suggests, HNSW searches a layered hierarchical graph to quickly identify neighborhoods of similar points to a given query vector. But is this hierarchy even necessary? A rigorous experimental analysis to answer this question would provide valuable insights into the nature of algorithm design for ANN search and motivate directions for future work in this increasingly crucial domain. To that end, we conduct an extensive benchmarking study covering more large-scale datasets than prior investigations of this question. We ultimately find that a flat navigable small world graph graph retains all of the benefits of HNSW on high-dimensional datasets, with latency and recall performance essentially identical to the original algorithm but with less memory overhead. Furthermore, we go a step further and study why the hierarchy of HNSW provides no benefit in high dimensions, hypothesizing that navigable small world graphs contain a well-connected, frequently traversed &apos;highway&apos; of hub nodes that maintain the same purported function as the hierarchical layers. We present compelling empirical evidence that the Hub Highway Hypothesis holds for real datasets and investigate the mechanisms by which the highway forms. The implications of this hypothesis may also provide future research directions in developing enhancements to graph-based ANN search.'\n",
      "date: 2025-01-22\n",
      "venue: '(Preprint)'\n",
      "paperurl: 'https://arxiv.org/pdf/2412.01940'\n",
      "citation: '<i>(Preprint)</i> <u>Blaise Munyampirwa</u>, Vihan Lakshman, Benjamin Coleman. <b>&amp;quot;Down with the Hierarchy: The &apos;H&apos; in HNSW stands for &apos;Hubs&apos;&amp;quot;</b>.'\n",
      "---\n",
      "Driven by recent breakthrough advances in neural representation learning, approximate near-neighbor (ANN) search over vector embeddings has emerged as a critical computational workload. With the introduction of the seminal Hierarchical Navigable Small World (HNSW) algorithm, graph-based indexes have established themselves as the overwhelmingly dominant paradigm for efficient and scalable ANN search. As the name suggests, HNSW searches a layered hierarchical graph to quickly identify neighborhoods of similar points to a given query vector. But is this hierarchy even necessary? A rigorous experimental analysis to answer this question would provide valuable insights into the nature of algorithm design for ANN search and motivate directions for future work in this increasingly crucial domain. To that end, we conduct an extensive benchmarking study covering more large-scale datasets than prior investigations of this question. We ultimately find that a flat navigable small world graph graph retains all of the benefits of HNSW on high-dimensional datasets, with latency and recall performance essentially identical to the original algorithm but with less memory overhead. Furthermore, we go a step further and study why the hierarchy of HNSW provides no benefit in high dimensions, hypothesizing that navigable small world graphs contain a well-connected, frequently traversed &apos;highway&apos; of hub nodes that maintain the same purported function as the hierarchical layers. We present compelling empirical evidence that the Hub Highway Hypothesis holds for real datasets and investigate the mechanisms by which the highway forms. The implications of this hypothesis may also provide future research directions in developing enhancements to graph-based ANN search.\n",
      "\n",
      "[Download](https://arxiv.org/pdf/2412.01940)\n",
      "\n",
      "Citation: <i>(Preprint)</i> <u>Blaise Munyampirwa</u>, Vihan Lakshman, Benjamin Coleman. <b>&quot;Down with the Hierarchy: The 'H' in HNSW stands for 'Hubs'&quot;</b>. "
     ]
    }
   ],
   "source": [
    "!cat ../_publications/2025-01-22-flatnav-paper.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
