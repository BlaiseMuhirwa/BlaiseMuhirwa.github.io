---
title: 'Reproducing Kernel Hilbert Spaces '
date: 2023-11-13
permalink: /posts/2012/08/blog-post-2/
tags:
  - Machine Learning 
  - Functional Analysis
---

In this blog we will examine what a Reproducing Kernel Hilbert Space (RKHS) is and the important properties that make them useful in statistical machine learning and functional analysis. Without loss of generality, we will take the general metric space $(\mathcal{X}, d)$ to 
be the standard Euclidean metric space $(\mathbb{R}^n, d)$. 

## What is a RKHS? 

A Reproducing Kernel Hilbert Space $\mathcal{H}$ is a Hilbert space of real-valued functions on $\mathcal{X}$ such that $\forall x \in \mathcal{X}$, the evaluation functional 

$$ L_x: \mathcal{H} \to \mathbb{R}$$

is bounded. That is, 

$$\forall x \in \mathcal{X}, \exists M \in \mathbb{R}$ \text{ s.t. } $||L_x(f)|| = ||f(x)|| \leq M ||f||_{\mathcal{H}}$ \text{ for all } $f \in \mathcal{H}$$

This is a slightly more abstract way of thinking about the RKHS, but there is also an alternative viewpoint that constructs a Hilbert space directly from a given kernel such that this space has the desired properties. We will explore this altenative construction at the end. 

$\textbf{Definition 1: A Hilbert Space}$, simply defined, is a complete [inner product space](https://en.wikipedia.org/wiki/Inner_product_space). Common examples include the space $\mathbb{R}^n, \mathbb{C}^n$, and $L^2[0,1]$, the space consisting of functions 

$$ f: [0,1] \to \mathbb{R}$$ 

that are Lebesgue-integrable and that satisfy the property that 

$$
\||f\||^2_{\mathcal{H}} = \int_{0}^{1} f^2(x)dx < \infty 
$$

$\textit{Proof}:$ We need to show that the space $L^2[0,1]$ satisfied the following conditions:
* Every cauchy sequence in $L^2[0,1]$ is convergent
* $L^2[0,1]$ is an inner-product space.


For $f, g \in L^2[0,1]$, we define 

$$
\langle f, g \rangle_{L^2[0,1]} = \int_{0}^{1} f(x)g(x)dx
$$

Clearly, $\langle .,. \rangle_{L^2[0,1]}$ is symmetric. We also notice that 

$$
\langle f, f \rangle_{L^2[0,1]} = \int_{0}^{1} f^2(x)dx = ||f||^2_{L^2[0,1]} \geq 0 
$$

Lastly, we also have that $\forall \alpha, \beta \in \mathbb{R}$ and $f, g, h \in L^2[0,1]$,

$$
\begin{align*}
\langle \alpha f + \beta g, h \rangle_{L^2[0,1]} &= \int_{0}^{1} \left[ \alpha f(x) + \beta g(x) \right] h(x) dx\\
&= \alpha \int_{0}^{1} f(x) h(x) dx + \beta \int_{0}^{1} g(x)h(x) dx \\
&= \alpha \langle f, h \rangle_{L^2[0,1]} + \beta \langle g, h \rangle_{L^2[0,1]}
\end{align*}
$$

This shows that $L^2[0,1]$ is indeed an inner-product space. Now let $\left( f_n\right)_{n=1}^{\infty}$ be a Cauchy sequence
in $L^2[0,1]$. This means that, in the function space norm, 

$$ \lim_{n \to \infty} ||f_n - f||^2 = \lim_{n\to\infty}\left( \int_{0}^{1} (f_n - f)^2\right) = 0$$

Instead of proving this directly, we indireclty show that this space is isomorphic to $l^2(\mathbb{N})$, the space of all 
square summable sequences, which is known to be complete. 

Let $(\phi_j)_{j=1}^{\infty}$ be an orthonormal basis for $L^2[0,1]$. That is, the basis satisfies the property that 

$$||\phi_j||_{L^2[0,1]} = 1 \forall j \in \mathbb{N} \text{ and } \langle \phi_i, \phi_j \rangle = 0 \text{ for all } i \neq j$$. 

Every $f \in L^2[0,1]$ can be represented as $f = \sum a_j\phi_j$ for some coefficients $(a_j)_{j}^{\infty}$ with $a_j = \langle f, \phi_j\rangle$. By Parseval's theorem ([Wainwright, 2019](https://www.cambridge.org/core/books/highdimensional-statistics/8A91ECEEC38F46DAB53E9FF8757C7A4E)), we have that 

$$|| f||^2_{L^2[0,1]} = \sum_{j=1}^{\infty}a_j^2$$

which shows that $f \in L^2[0,1] \iff (a_j)_{j=1}^{\infty} \in l^2(\mathbb{N})$. It is due to this isomorphism that we can conclude that 
$L^2[0,1]$ is also complete. 

## How large is the class of RKHS's? 















